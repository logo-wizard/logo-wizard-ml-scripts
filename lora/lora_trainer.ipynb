{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-dotenv transformers datasets==2.10.0 accelerate wandb git+https://github.com/huggingface/diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "read_token = os.environ[\"READ_HF_TOKEN\"]\n",
    "write_token = os.environ[\"WRITE_HF_TOKEN\"]\n",
    "os.system(f\"!huggingface-cli login --token {write_token}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гиперпараметры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_path = \"stabilityai/stable-diffusion-2-1-base\"\n",
    "dataset_path = \"logo-wizard/modern-logo-dataset\"\n",
    "image_resolution = 512\n",
    "batch_size = 16\n",
    "grad_accum_steps = 1\n",
    "train_steps = 10000\n",
    "lr = 1e-4\n",
    "scheduler = \"cosine\"\n",
    "output_dir = \"/lora\"\n",
    "final_lora_name = \"logo-diffusion-lora\"\n",
    "checpointing_steps = 500\n",
    "val_prompt = \"Logo of bakery with pretzel.\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Запуск обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system(\n",
    "    f\"accelerate launch --mixed_precision='fp16'  lora_finetune_script.py \\\n",
    "  --pretrained_model_name_or_path={base_model_path} \\\n",
    "  --dataset_name={dataset_path} \\\n",
    "  --dataloader_num_workers=8 \\\n",
    "  --resolution={image_resolution} --center_crop --random_flip \\\n",
    "  --train_batch_size={batch_size} \\\n",
    "  --gradient_accumulation_steps={grad_accum_steps} \\\n",
    "  --max_train_steps={train_steps} \\\n",
    "  --learning_rate={lr} \\\n",
    "  --max_grad_norm=1 \\\n",
    "  --lr_scheduler={scheduler} --lr_warmup_steps=0 \\\n",
    "  --output_dir={output_dir} \\\n",
    "  --push_to_hub \\\n",
    "  --hub_model_id={final_lora_name} \\\n",
    "  --report_to=wandb \\\n",
    "  --checkpointing_steps={checpointing_steps} \\\n",
    "  --validation_prompt={val_prompt} \\\n",
    "  --enable_xformers_memory_efficient_attention \\\n",
    "  --seed=42\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
